# VLLMModelHosting

A Dockerfile with companion start.sh used for Build on platforms like Koyeb

An additional run_optimised_vllm.sh script inspired by run_model.sh used by Digital Ocean for their inference optimised Droplets. To be used on either bare metal or cloud nodes running Open Weight models
